import os
from dotenv import load_dotenv
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.document_loaders import UnstructuredMarkdownLoader
from langchain_upstage import UpstageEmbeddings
from langchain_pinecone import PineconeVectorStore
from pinecone import Pinecone, ServerlessSpec

# 1. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
pinecone_api_key = os.environ.get("PINECONE_API_KEY")
pc = Pinecone(api_key=pinecone_api_key)

# 2. ì„ë² ë”© ëª¨ë¸
embedding_upstage = UpstageEmbeddings(model="embedding-query")

# 3. í…ìŠ¤íŠ¸ ë¶„í• ê¸°
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=600,
    chunk_overlap=50
)

# 4. ë©”íƒ€ë°ì´í„° íŒŒì‹± í•¨ìˆ˜
def extract_metadata_from_md(path: str):
    with open(path, "r", encoding="utf-8") as f:
        lines = f.readlines()

    category = None
    keywords = []

    for line in lines:
        line = line.strip()
        if line.startswith("ì¹´í…Œê³ ë¦¬:"):
            category = line.replace("ì¹´í…Œê³ ë¦¬:", "").strip()
        elif line.startswith("í‚¤ì›Œë“œ:"):
            keyword_raw = line.replace("í‚¤ì›Œë“œ:", "").strip()
            keyword_raw = keyword_raw.strip("[]")
            keywords = [kw.strip() for kw in keyword_raw.split(",") if kw.strip()]
        if category and keywords:
            break

    return category, keywords

# 5. í´ë”ë³„ ë¬¸ì„œ íŒŒì‹± ë° ì—…ë¡œë“œ
def process_and_upload_by_folder(base_dir: str):
    category_docs_map = {}

    for root, dirs, files in os.walk(base_dir):
        for file in files:
            if file.endswith(".md"):
                full_path = os.path.join(root, file)
                mid_folder = os.path.basename(os.path.dirname(full_path))
                print(f"ğŸ“„ ì²˜ë¦¬ ì¤‘: {full_path}")

                category, keywords = extract_metadata_from_md(full_path)
                loader = UnstructuredMarkdownLoader(full_path)
                docs = loader.load()
                split_docs = text_splitter.split_documents(docs)

                for doc in split_docs:
                    doc.metadata["category"] = category
                    doc.metadata["keyword"] = keywords

                if mid_folder not in category_docs_map:
                    category_docs_map[mid_folder] = []
                category_docs_map[mid_folder].extend(split_docs)

    # í´ë”ë³„ë¡œ Pinecone ì¸ë±ìŠ¤ ìƒì„± ë° ì—…ë¡œë“œ
    for folder_name, docs in category_docs_map.items():
        index_name = f"cs-{folder_name.lower()}-index"

        if index_name not in pc.list_indexes().names():
            pc.create_index(
                name=index_name,
                dimension=4096,
                metric="cosine",
                spec=ServerlessSpec(cloud="aws", region="us-east-1"),
            )

        print(f"ğŸ“¤ ì—…ë¡œë“œ ì¤‘: {folder_name} â†’ {index_name} ({len(docs)} chunks)")
        PineconeVectorStore.from_documents(docs, embedding_upstage, index_name=index_name)
        print(f"âœ… ì™„ë£Œ: {folder_name} ì—…ë¡œë“œ")

# 6. ì‹¤í–‰
print("ğŸš€ Markdown íŒŒì‹± ë° ì¹´í…Œê³ ë¦¬ë³„ ì—…ë¡œë“œ ì‹œì‘...")
process_and_upload_by_folder("DB/")
print("âœ… ì „ì²´ ì™„ë£Œ")
